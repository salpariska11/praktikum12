# ANALISIS KODE PROGRAM
## build_embeddings.py ##
Program `build_embeddings.py` berfungsi untuk mengekstraksi embedding wajah dari semua gambar yang berada di dalam folder `data/train`. Proses ini dimulai dengan mengimpor beberapa pustaka yang diperlukan seperti `os`, `glob`, `numpy`, dan `tqdm`, serta fungsi `embed_from_path` dari modul `utils_facenet.py`. Fungsi `iter_images()` digunakan untuk menelusuri seluruh folder kelas (misalnya nama orang seperti *rizal* atau *salva*) dan mengumpulkan path setiap gambar di dalamnya. Dengan cara ini, program dapat secara otomatis membaca seluruh dataset tanpa perlu memasukkan nama file satu per satu. Selanjutnya, fungsi `build_matrix()` akan memanggil fungsi `embed_from_path()` untuk setiap gambar. Fungsi tersebut mendeteksi wajah menggunakan MTCNN dan menghasilkan embedding FaceNet berdimensi 512. Jika wajah tidak terdeteksi, gambar tersebut dicatat dalam daftar `bad`. Jika berhasil, embedding dimasukkan ke dalam list `X` dan labelnya (nama folder) dimasukkan ke list `y`. Setelah seluruh proses selesai, data dikonversi menjadi array NumPy.

Pada bagian utama program (`if __name__ == "__main__":`), proses dimulai dengan menampilkan informasi bahwa ekstraksi embedding sedang berjalan. Kemudian `build_matrix("data/train")` dipanggil untuk menghasilkan tiga keluaran: embedding (`X`), label (`y`), dan daftar gambar gagal deteksi (`bad`). Program menampilkan jumlah embedding yang dihasilkan, jumlah label, dan jumlah gambar yang tidak berhasil diproses. Akhirnya, embedding dan label disimpan ke file `X_train.npy` dan `y_train.npy` menggunakan `numpy.save()`. File `.npy` inilah yang nantinya digunakan untuk melatih model SVM pada tahap berikutnya. Program ditutup dengan pesan sukses bahwa proses ekstraksi embedding telah selesai.
## predict_one.py ##
Program predict_one.py digunakan untuk melakukan prediksi identitas wajah pada satu gambar menggunakan model SVM yang sebelumnya telah dilatih. Di awal program, model klasifikasi dimuat menggunakan joblib.load("facenet_svm.joblib"), yang berarti program akan menggunakan model SVM hasil training untuk mengenali embedding wajah. Fungsi utama dalam file ini adalah predict_image(), yang menerima path gambar sebagai input lalu mengekstraksi embedding wajah melalui fungsi embed_from_path dari modul utils_facenet.py. Jika wajah tidak ditemukan pada gambar, fungsi langsung mengembalikan nilai "NO_FACE" dengan confidence 0.0 sebagai indikasi bahwa proses gagal mendeteksi wajah.

Setelah embedding berhasil diperoleh, program menghitung probabilitas prediksi dengan memanggil clf.predict_proba([emb]), kemudian menentukan kelas dengan probabilitas tertinggi. Model SVM memberikan dua output penting: label yaitu nama orang yang paling mungkin cocok dengan wajah dalam gambar, serta conf yaitu tingkat keyakinan model terhadap prediksi tersebut. Program juga menerapkan ambang batas (unknown_threshold) sebesar 0.55. Jika nilai confidence berada di bawah batas ini, gambar dianggap tidak cocok dengan identitas mana pun yang diketahui, sehingga hasilnya ditandai sebagai "UNKNOWN".

Pada bagian akhir, blok if __name__ == "__main__": menjalankan program secara langsung dengan menentukan path gambar uji, dalam contoh ini data/val/salva/salpa2.jpg. Setelah fungsi prediksi dijalankan, hasil berupa label dan tingkat confidence ditampilkan ke terminal menggunakan print(). Dengan demikian, file ini berfungsi sebagai alat uji sederhana untuk mengetahui apakah model dapat mengenali identitas dari satu gambar tertentu berdasarkan embedding FaceNet dan klasifikasi SVM.
## train_classifier ##
Program train_classifier.py bertugas untuk melatih model klasifikasi wajah menggunakan embedding yang sebelumnya telah dihasilkan oleh FaceNet. Proses dimulai dengan memuat dua file penting, yaitu X_train.npy yang berisi embedding berdimensi 512 dari setiap wajah, dan y_train.npy yang berisi label nama orang untuk setiap embedding. Dengan demikian, kedua file tersebut berfungsi sebagai dataset untuk proses training. Setelah itu, program membangun sebuah pipeline machine learning yang terdiri dari dua tahap utama: normalisasi data menggunakan StandardScaler dan model klasifikasi SVC (Support Vector Machine) dengan kernel RBF. Normalisasi diperlukan agar semua fitur embedding memiliki skala yang seragam, sementara SVM digunakan untuk membedakan identitas wajah berdasarkan pola dalam embedding.

Selanjutnya, program melakukan evaluasi awal terhadap performa model menggunakan cross-validation dengan pembagian dua fold (cv=2). Penggunaan dua fold dipilih karena jumlah data pelatihan yang sangat sedikit, sehingga pembagian lima fold (cv=5) tidak memungkinkan. Hasil cross-validation ditampilkan dalam bentuk rata-rata akurasi beserta standar deviasinya, sehingga pengguna dapat memahami seberapa stabil performa model pada data kecil tersebut. Setelah tahap evaluasi, model kemudian dilatih secara penuh menggunakan seluruh dataset, dan hasil pelatihan disimpan dalam file facenet_svm.joblib menggunakan joblib.dump(). File ini akan digunakan oleh program prediksi (predict_one.py) untuk mengenali identitas wajah pada gambar baru. Program ditutup dengan pesan sukses sebagai penanda bahwa model telah berhasil dilatih dan siap dipakai.
## utils_facenet.py ##
File utils_facenet.py berfungsi sebagai modul inti yang menangani seluruh proses deteksi wajah, alignment, dan ekstraksi embedding wajah menggunakan FaceNet. Program dimulai dengan mengimpor beberapa pustaka penting seperti torch, numpy, cv2, PIL, dan modul-model dari facenet_pytorch. Perintah pertama menentukan apakah perangkat menggunakan GPU (cuda) atau CPU, sehingga proses dapat berjalan lebih cepat jika GPU tersedia. Modul MTCNN kemudian diinisialisasi untuk mendeteksi wajah dan melakukan alignment dengan ukuran standar 160x160 piksel, sementara model FaceNet (InceptionResnetV1) dimuat dengan bobot pre-trained dari dataset VGGFace2 untuk menghasilkan embedding wajah berdimensi 512.

Fungsi read_img_bgr() digunakan untuk membaca gambar dalam format BGR menggunakan OpenCV. Jika gambar gagal dibaca, program langsung memberikan error yang mudah dipahami. Fungsi bgr_to_pil() mengonversi format gambar OpenCV (BGR) ke gambar PIL (RGB), karena MTCNN bekerja menggunakan format PIL. Proses alignment wajah dilakukan oleh fungsi face_align(), yang menjalankan MTCNN pada gambar yang telah dikonversi, dan hasilnya berupa tensor wajah ter-crop yang sudah lurus dan siap diproses lebih lanjut. Jika tidak ditemukan wajah pada gambar, fungsi mengembalikan None.

Setelah wajah berhasil di-align, fungsi embed_face_tensor() mengubah tensor wajah menjadi embedding FaceNet berukuran 512 dimensi. Embedding ini merupakan representasi numerik unik dari wajah, yang dapat digunakan untuk identifikasi maupun verifikasi. Fungsi embed_from_path() menyederhanakan seluruh proses dengan menggabungkan langkah-langkah: membaca gambar, melakukan alignment, dan menghasilkan embedding hanya dari path file gambar. Di akhir, fungsi cosine_similarity() disertakan untuk menghitung tingkat kemiripan antara dua embedding wajah, yang sangat berguna dalam verifikasi 1:1. Secara keseluruhan, file ini adalah pondasi utama sistem FaceNet, karena seluruh proses deteksi dan ekstraksi fitur wajah dilakukan di sini.
## verify_pair.py ##
Program verify_pair.py digunakan untuk melakukan proses verifikasi wajah 1:1, yaitu membandingkan dua gambar apakah berasal dari orang yang sama atau tidak. Di awal program, fungsi embed_from_path dan cosine_similarity diimpor dari modul utils_facenet.py, karena kedua fungsi tersebut merupakan komponen utama yang menangani pembacaan gambar, deteksi wajah, ekstraksi embedding FaceNet, serta perhitungan tingkat kemiripan antar embedding. Dua variabel img1 dan img2 berisi jalur file gambar yang akan dibandingkan, misalnya dua foto milik orang yang sama (contoh: folder rizal). Pengguna dapat mengganti path tersebut sesuai foto yang ingin diuji.

Setelah itu, program memanggil embed_from_path() untuk mendapatkan embedding dari masing-masing gambar. Jika salah satu gambar tidak menghasilkan embedding—misalnya karena wajah tidak terdeteksi, gambar terlalu gelap, atau resolusi wajah kecil—program langsung menampilkan pesan error bahwa wajah gagal dideteksi. Namun jika embedding dari kedua gambar tersedia, program melanjutkan proses perhitungan tingkat kemiripan menggunakan fungsi cosine_similarity(), yang menghasilkan nilai antara -1 hingga 1. Nilai ini menunjukkan seberapa mirip dua wajah menurut FaceNet, di mana angka mendekati 1 berarti semakin mirip.

Program kemudian membandingkan nilai kemiripan tersebut dengan sebuah ambang batas (threshold) sebesar 0.85. Jika similarity bernilai sama atau lebih besar dari 0.85, program menampilkan bahwa kedua gambar dianggap “Match” atau cocok, artinya berasal dari orang yang sama. Sebaliknya, jika nilai similarity di bawah threshold, program menyimpulkan bahwa kedua wajah tidak sama. Dengan demikian, verify_pair.py menjadi alat sederhana namun efektif untuk melakukan verifikasi wajah berbasis embedding FaceNet.
